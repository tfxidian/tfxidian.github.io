---
title: CUDA中的Unified Memory
date: 2021-08-14 16:15:50
tags: CUDA, UMA
layout: post
---
## 异构计算
![](https://res-static.hc-cdn.cn/fms/img/04c86054e431a504f1eb111c752fe1901614894793661)

GPU包括更多的运算核心，其特别适合数据并行的计算密集型任务，如大型矩阵运算，而CPU的运算核心较少，但是其可以实现复杂的逻辑运算，因此其适合控制密集型任务。另外，CPU上的线程是重量级的，上下文切换开销大，但是GPU由于存在很多核心，其线程是轻量级的。因此，基于CPU+GPU的异构计算平台可以优势互补，CPU负责处理逻辑复杂的串行程序，而GPU重点处理数据密集型的并行计算程序，从而发挥最大功效。
## unified memory
*统一内存是可从系统中的任何处理器访问的单个内存地址空间.*
在CUDA 6中，NVIDIA引入了CUDA历史上一个最重要的一个编程模型改进之一，unified memory(统一内存)。今天典型的PC上，CPU与GPU的内存是物理上独立的，通过PCIe总线进行连接通信。实际上，在CUDA 6.0之前，程序员必须在编程期间很清楚这一点，并且反应在代码中。必须在CPU和GPU两端都进行内存分配，并不断地进行手动copy，来保证两端的内存一致。
Unified memory在程序员的视角中，维护了一个统一的内存池，在CPU与GPU中共享。使用了单一指针进行托管内存，由系统来自动地进行内存迁移。

*传统CPU中的排序算法*
```
void sortfile(FILE *fp, int N)                                          
{                                                    
    char *data;                                          
    data = (char*)malloc(N);                           
    fread(data, 1, N, fp);                               
    qsort(data, N, 1, compare);                                           
    usedata(data);                                       
    free(data);                                          
}
```

*在cuda中unified memory出现之前*
```
void sortfile(FILE *fp, int N)    
{
    char *h_data, *d_data;                                        
    h_data= (char*)malloc(N); 
    cudaMalloc(&d_data, N);

    fread(h_data, 1, N, fp);  

    cudaMemcpy(d_data, h_data, N, cudaMemcpyHostToDevice);

    qsort<<<...>>>(data, N, 1, compare);

    cudaMemcpy(h_data, h_data, N, cudaMemcpyDeviceToHost);  //不需要手动进行同步，该函数内部会在传输数据前进行同步
    
    usedata(data);
    free(data); 
}

```

*在cuda中unified memory出现以后*

```
void sortfile(FILE *fp, int N)                   
{
    char *data;  
    cudaMallocManaged(data, N);
    fread(data, 1, N, fp); 
    qsort<<<...>>>(data, N, 1, compare);
    cudaDeviceSynchronize();
    usedata(data);
    free(data);
}
```

到目前为止，可以看出主要有以下的优势：

- 简化了代码编写和内存模型
- 可以在CPU端和GPU端共用一个指针，不用单独各自分配空间。方便管理，减少了代码量。
- 语言结合更紧密，减少与兼容语言的语法差异。
- 更方便的代码迁移。


## unified memory


 ![](https://github.com/tfxidian/tfxidian.github.io/raw/master/pic/simple-process-flow.png)

### 传统xPU数据处理过程
![](https://res-static.hc-cdn.cn/fms/img/5f18f271a657765d37dfe019f45458711614894793661)
一个简单的数据处理流程
- 从CPU内存中拷贝数据到GPU内存
- 加载GPU程序执行
- 从GPU内存中拷贝结果到CPU
  

### unified memory 数据处理过程










[](https://zhuanlan.zhihu.com/p/82651065)
